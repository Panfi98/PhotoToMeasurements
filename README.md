# Photo to Measurements

Proof of concept for estimating human body measurements (chest, hips, inseam, sleeve length, etc.) from:
- 1 front photo
- 1 side photo  
- Declared body height

---

## ğŸš€ Quick Start

```bash
# 1. Create virtual environment
python3 -m venv venv
source venv/bin/activate

# 2. Install dependencies
pip install opencv-python mediapipe numpy

# 3. Run on a subject
python src/run.py
```

---

## ğŸ“ Project Structure

```
PhotoToMeasurements/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ run.py              # Main processing script
â”œâ”€â”€ input/
â”‚   â””â”€â”€ subject_01/         # Input images go here
â”‚       â”œâ”€â”€ front_side.JPG  # Front-facing photo
â”‚       â””â”€â”€ meta.json       # Subject metadata
â”œâ”€â”€ output/
â”‚   â””â”€â”€ subject_01/         # Generated outputs
â”‚       â”œâ”€â”€ front_pose.jpg       # Image with skeleton overlay
â”‚       â”œâ”€â”€ front_mask.png       # Person segmentation mask
â”‚       â”œâ”€â”€ front_mask_overlay.jpg  # Segmentation visualization
â”‚       â””â”€â”€ quality.json         # Detection quality metrics
â””â”€â”€ README.md
```

---

## ğŸ”„ How It Works (Step by Step)

### Input
You provide a front-facing photo of a person.

### Step 1: Pose Detection
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Photo    â”‚ â”€â”€â–¶ â”‚  MediaPipe Pose  â”‚ â”€â”€â–¶ â”‚  33 Body Points â”‚
â”‚   (front.jpg)   â”‚     â”‚  Neural Network  â”‚     â”‚  (x, y coords)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The pose model finds **33 keypoints** on the body:
- Face: nose, eyes, ears, mouth
- Upper body: shoulders, elbows, wrists
- Torso: hips
- Lower body: knees, ankles, feet

**Output:** `front_pose.jpg` - your photo with a skeleton drawn on it

### Step 2: Person Segmentation
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Photo    â”‚ â”€â”€â–¶ â”‚ Selfie Segmenter â”‚ â”€â”€â–¶ â”‚  Binary Mask    â”‚
â”‚   (front.jpg)   â”‚     â”‚  Neural Network  â”‚     â”‚  (person=white) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The segmentation model creates a **mask** showing where the person is:
- White pixels = person
- Black pixels = background

**Outputs:**
- `front_mask.png` - the raw mask
- `front_mask_overlay.jpg` - green overlay showing detected person area

### Step 3: Quality Check
```json
{
  "pose_has_landmarks": true,   // Was a person detected?
  "segmentation_mean": 207.7    // How much of image is person
}
```

---

## ğŸ§  What Happens Inside the Neural Networks?

```
        YOUR IMAGE                    NEURAL NETWORK                    OUTPUT
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚            â”‚  Layer 1: Features  â”‚         â”‚              â”‚
    â”‚  RGB Pixels   â”‚            â”‚  Layer 2: Patterns  â”‚         â”‚  Keypoints   â”‚
    â”‚  3024 x 4032  â”‚  â”€â”€â”€â”€â”€â”€â–¶   â”‚  Layer 3: Body Partsâ”‚  â”€â”€â”€â”€â–¶  â”‚     or       â”‚
    â”‚  = 12M pixels â”‚            â”‚  Layer 4: Positions â”‚         â”‚    Mask      â”‚
    â”‚               â”‚            â”‚         ...         â”‚         â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         
    Image becomes                Network learned from              Structured
    a number array               millions of photos                predictions
```

1. **Image â†’ Tensor**: Photo converted to numbers (RGB values 0-255)
2. **Forward Pass**: Numbers flow through network layers
3. **Prediction**: Network outputs coordinates or pixel classifications

---

## ğŸ¯ Core Design Principles

| Principle | Description |
|-----------|-------------|
| **Fail Fast** | Reject bad images before attempting measurements |
| **Geometry First** | Use actual coordinates, not black-box guessing |
| **Confidence Scores** | Every measurement has a reliability score |
| **Debuggable** | All steps produce visual outputs you can inspect |

---

## ğŸ“Š Current Capabilities

- [x] Pose landmark detection (33 body keypoints)
- [x] Person segmentation (foreground/background separation)
- [x] Quality metrics output
- [ ] Actual body measurements (coming soon)
- [ ] Side photo processing (coming soon)
- [ ] Height calibration (coming soon)

---

## ğŸ› ï¸ Technical Details

### Dependencies
- **OpenCV** - Image reading/writing and processing
- **MediaPipe** - Google's ML models for pose and segmentation
- **NumPy** - Array operations

### Models Used
| Model | File | Purpose |
|-------|------|---------|
| Pose Landmarker | `pose_landmarker.task` | Detects 33 body keypoints |
| Selfie Segmenter | `selfie_segmenter.tflite` | Separates person from background |

Models are automatically downloaded on first run (~5MB total).